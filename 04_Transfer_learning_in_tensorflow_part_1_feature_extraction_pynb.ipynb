{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-Transfer-learning-in-tensorflow-part-1-feature-extraction.pynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNX20rfhq6J1v2HpTwMGNi+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tower5954/TensorFlow/blob/main/04_Transfer_learning_in_tensorflow_part_1_feature_extraction_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr0ztOmoyW0A"
      },
      "source": [
        "# Transfer learning with TensorFlow part 1: Feature extraction.\n",
        "\n",
        "Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problem.\n",
        "\n",
        "There are 2 main benefits:\n",
        "\n",
        "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIfVE6322euw",
        "outputId": "8ef16bb5-dc98-4d89-8c14-ac15591f807c"
      },
      "source": [
        "# Are we using a GPU?\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 13 19:10:36 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySMubJoH25WO"
      },
      "source": [
        "## Downloading and becoming one with the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4KIFapl3JbM",
        "outputId": "0cf661f8-c8bf-4888-b230-140e362ba49e"
      },
      "source": [
        "# Get data (10% of 10 food classes from Food101)\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-13 19:10:36--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.192.128, 172.217.219.128, 209.85.147.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.192.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  91.9MB/s    in 1.7s    \n",
            "\n",
            "2021-12-13 19:10:38 (91.9 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpAUw8HJ5Mvl",
        "outputId": "2a484343-f820-4349-ccb8-e7b4fc2ce4a5"
      },
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "# Walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are: {len(dirnames)} directories and {len(filenames)} images in '{dirpath}' \")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are: 2 directories and 0 images in '10_food_classes_10_percent' \n",
            "There are: 10 directories and 0 images in '10_food_classes_10_percent/train' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/pizza' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/ramen' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/sushi' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/steak' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice' \n",
            "There are: 10 directories and 0 images in '10_food_classes_10_percent/test' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/pizza' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/ramen' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/sushi' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/steak' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice' \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create data loaders (preparing the data)\n",
        "\n",
        "We will use the `ImageDataGenerator` class to load in our images in batches "
      ],
      "metadata": {
        "id": "KzOchzj36o4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up data inputs\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224,224)\n",
        "BATCH_SIZE = (32)\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMAGE_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMAGE_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjPCLy5-8BXf",
        "outputId": "ce2a09f1-aeee-432e-8b7f-394d8db5d25a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run while the model trains)\n",
        "\n",
        "Callbacks are extra functionality you can add to a model to be performed during or after training. Some of the more popular callbacks are:\n",
        "* Tracking experiments with the TensorBoard callback.\n",
        "* Model checkpoint with the ModelCheckpoint callback.\n",
        "* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nPOVdaj0-yKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback (functionised to allow for creating a new one for each model)"
      ],
      "metadata": {
        "id": "Z4HybvrzkWGT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" +experiment_name + \"/\" + datetime.datetime.now().strftime('%d%m%Y-%H%M')\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir)\n",
        "  print(f\"Saving Tensorboard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "MJ3I92bWnc_2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔑 **Note**: 🔑 You can customise the directory where your TensorBoard logs(model training metrics)gets saved to wherever you like. The `log_dir` parameter created above is just one option. "
      ],
      "metadata": {
        "id": "80n4AoKfphKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "\n",
        "In the past we have used TensorFlow to create our own models layer by layer from scratch.\n",
        "\n",
        "Now we are going to do a similar process, except the majority of our model's layers are going to come from TensorFlow Hub.\n",
        "\n",
        "We can access pretrained models on: https://tfhub.dev/\n",
        "\n",
        "Browsing the TensorFlow Hub page and sorting for image classification, we found the following feature vector model link:\n",
        "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1"
      ],
      "metadata": {
        "id": "CL3OcIAxscEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔑 Note: Comparing different model architecture performance on the same data is a very common practice. The simple reason is because you want to know which model performs best for your problem.\n",
        "\n",
        "Update: As of 14 August 2021, EfficientNet V2 pretrained models are available on TensorFlow Hub. The original code in this notebook uses EfficientNet V1, it has been left unchanged. In my experiments with this dataset, V1 outperforms V2. Best to experiment with your own data and see what suits you."
      ],
      "metadata": {
        "id": "ijYm4oWAx56-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the following models:\n",
        "\n",
        "\n",
        "# Resnet 50 V2 feature vector\n",
        "resnet_url = 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4'\n",
        "\n",
        "# Original: EfficientNetB0 feature vector (version 1)\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
        "\n",
        "# # New: EfficientNetB0 feature vector (version 2)\n",
        "# efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\""
      ],
      "metadata": {
        "id": "7_QfDqVroWan"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers "
      ],
      "metadata": {
        "id": "OK-DI1WgyQdP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a make_model() function to create a model from a URL\n",
        "\n",
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"\n",
        "  Takes a TensorFlow Hub URL and creates a keras Sequential model with it.\n",
        "\n",
        "  Args: \n",
        "      model_url (str): A Tensorflow Hub feature extraction URL.\n",
        "      num_classes (int): Number of output neurons in the output layer,\n",
        "      should be equal to number of target classes, default is 10.\n",
        "\n",
        "  Returns:\n",
        "      An uncompiled Keras Sequential model with model_url as feature extractor \n",
        "      layer and dense output layer with num_classes output neurons. \n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a kera slayer\n",
        "  feature_extracor_layer = hub.KerasLayer(model_url,\n",
        "                                          trainable=False, # Freeze the already trained patterns.\n",
        "                                          name='feature_extraction_layer',\n",
        "                                          input_shape=IMAGE_SHAPE + (3,)) \n",
        "  \n",
        "  # Create a model\n",
        "  model = tf.keras.Sequential([\n",
        "                  feature_extracor_layer,\n",
        "                  layers.Dense(num_classes, activation='softmax', name='output_layer')\n",
        "  ])\n",
        "\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "2GDs9pq95Rg5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and Testing a ResNet TensorFlow Hub Feature Extraction model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3A7Uca7BQYrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = create_model(resnet_url)"
      ],
      "metadata": {
        "id": "wGTbmogbQTGg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i83tt3zRAO8",
        "outputId": "fd6fb6c7-d8b5-46d8-a6af-e25d1568de93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (K  (None, 2048)             23564800  \n",
            " erasLayer)                                                      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(loss=\"categorical_crossentropy\",\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "qm5IiVn2R1BL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.util.dispatch import dispatch_for_unary_elementwise_apis\n",
        "# Fitting the ResNet model to the data (10 percent of 10 classes)\n",
        "\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_percent),\n",
        "                                  validation_data=test_data,\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                                         experiment_name=\"resnet50v2\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VF5u6aNSqXF",
        "outputId": "5803c731-acf6-4bd4-dcc1-bd6dd6158630"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: tensorflow_hub/resnet50v2/13122021-1941\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 43s 1s/step - loss: 1.8698 - accuracy: 0.3853 - val_loss: 1.1577 - val_accuracy: 0.6352\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 24s 1s/step - loss: 0.8760 - accuracy: 0.7373 - val_loss: 0.8502 - val_accuracy: 0.7256\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 24s 1s/step - loss: 0.6070 - accuracy: 0.8227 - val_loss: 0.7422 - val_accuracy: 0.7656\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 24s 1s/step - loss: 0.4661 - accuracy: 0.8760 - val_loss: 0.7050 - val_accuracy: 0.7728\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 24s 1s/step - loss: 0.3743 - accuracy: 0.9173 - val_loss: 0.6726 - val_accuracy: 0.7856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transfer learning feature extractor model out performed all previous models\n",
        "we built by hand and in a quicker training time and with only 10%\n",
        "of the training examples."
      ],
      "metadata": {
        "id": "2zuOrte6UIZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to plot loss curves.\n"
      ],
      "metadata": {
        "id": "9fbLRhaZXOFF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}