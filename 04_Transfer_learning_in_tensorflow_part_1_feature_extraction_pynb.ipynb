{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-Transfer-learning-in-tensorflow-part-1-feature-extraction.pynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNIYdNAmoWxI4pvCwJuLW2g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tower5954/TensorFlow/blob/main/04_Transfer_learning_in_tensorflow_part_1_feature_extraction_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr0ztOmoyW0A"
      },
      "source": [
        "# Transfer learning with TensorFlow part 1: Feature extraction.\n",
        "\n",
        "Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problem.\n",
        "\n",
        "There are 2 main benefits:\n",
        "\n",
        "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIfVE6322euw",
        "outputId": "5ce87c08-ea5c-446c-986e-02cd211749c1"
      },
      "source": [
        "# Are we using a GPU?\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec 11 03:36:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P8    35W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySMubJoH25WO"
      },
      "source": [
        "## Downloading and becoming one with the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4KIFapl3JbM",
        "outputId": "743cce87-ba9a-484c-c16e-10a6c22f749c"
      },
      "source": [
        "# Get data (10% of 10 food classes from Food101)\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-11 03:36:24--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.97.128, 108.177.125.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  51.2MB/s    in 3.1s    \n",
            "\n",
            "2021-12-11 03:36:28 (51.2 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpAUw8HJ5Mvl",
        "outputId": "b2ad5edc-4678-4486-9cc8-56f5bf8e843f"
      },
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "# Walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are: {len(dirnames)} directories and {len(filenames)} images in '{dirpath}' \")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are: 2 directories and 0 images in '10_food_classes_10_percent' \n",
            "There are: 10 directories and 0 images in '10_food_classes_10_percent/test' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/sushi' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/pizza' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/steak' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/ramen' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry' \n",
            "There are: 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon' \n",
            "There are: 10 directories and 0 images in '10_food_classes_10_percent/train' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/sushi' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/pizza' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/steak' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/ramen' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry' \n",
            "There are: 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon' \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create data loaders (preparing the data)\n",
        "\n",
        "We will use the `ImageDataGenerator` class to load in our images in batches "
      ],
      "metadata": {
        "id": "KzOchzj36o4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up data inputs\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224,224)\n",
        "BATCH_SIZE = (32)\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMAGE_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMAGE_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjPCLy5-8BXf",
        "outputId": "8321a995-1f75-4a52-d6e7-3e86a22f1dd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run while the model trains)\n",
        "\n",
        "Callbacks are extra functionality you can add to a model to be performed during or after training. Some of the more popular callbacks are:\n",
        "* Tracking experiments with the TensorBoard callback.\n",
        "* Model checkpoint with the ModelCheckpoint callback.\n",
        "* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nPOVdaj0-yKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback (functionised to allow for creating a new one for each model)"
      ],
      "metadata": {
        "id": "Z4HybvrzkWGT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" +experiment_name + \"/\" + datetime.datetime.now().strftime('%d%m%Y-%H%M')\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir)\n",
        "  print(f\"Saving Tensorboard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "MJ3I92bWnc_2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔑 **Note**: 🔑 You can customise the directory where your TensorBoard logs(model training metrics)gets saved to wherever you like. The `log_dir` parameter created above is just one option. "
      ],
      "metadata": {
        "id": "80n4AoKfphKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CL3OcIAxscEo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}